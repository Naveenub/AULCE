# AULCE ðŸš€

> **A researchâ€‘grade, openâ€‘source, lossless universal compression system inspired by (but not copying) the HBO *Silicon Valley* concept.**

AULCE is **not magic** and **not a single algorithm**. It is a *system*: a multiâ€‘pipeline, MLâ€‘assisted compression framework that **selects, composes, and validates optimal lossless strategies per file type**, with explainability via RAG and strong benchmarking discipline.

---

## Introduction

Classic compressors (ZIP, TAR.GZ, 7z, Zstd) apply *general heuristics*. Realâ€‘world data is heterogeneous: PDFs, logs, CSVs, images, binaries, audio, and alreadyâ€‘compressed blobs behave very differently.

**AULCE** treats compression as a *decision problem*:

> *Given a file (or corpus), which lossless strategyâ€”or chain of strategiesâ€”minimizes size while guaranteeing reversibility?*

Instead of promising impossible ratios, we focus on:

* smarter selection
* hybrid pipelines
* empirical guarantees
* transparent failure explanations

---

## Available Today vs Whatâ€™s New

### Existing Tools

| Tool   | Strength   | Limitation    |
| ------ | ---------- | ------------- |
| ZIP    | Ubiquitous | Weak ratios   |
| TAR.GZ | Simple     | No adaptivity |
| 7z     | Strong     | Slow, opaque  |
| Zstd   | Fast       | Not universal |

---

## Core Design Goals

1. **Strictly lossless** (bitâ€‘perfect roundâ€‘trip)
2. **Universal** (any file extension)
3. **Composable** (pipelines, not monoliths)
4. **Explainable** (why compression succeeded or failed)
5. **Benchmarkâ€‘driven** (no marketing ratios)
6. **Open & inspectable** (no black boxes)

---

## Model Overview (ML Strategy Selector)

The ML model does **not** compress data directly.

It predicts:

* which *pipeline* to apply
* expected compression ratio
* expected time/memory cost
* probability of improvement vs baseline

### Input Features

* Byte entropy
* Nâ€‘gram redundancy
* File magic + MIME
* Size distribution
* Symbol frequency skew
* Prior compression signals

### Output

```json
{
  "pipeline": "pdf â†’ objectâ€‘stream â†’ zstd",
  "expected_ratio": 2.14,
  "confidence": 0.82
}
```

---

## System Overview

AULCE is a **modular system**, not a single binary.

```text
              Upload
                â”‚
                â–¼
             Analyzer
                â”‚
                â–¼
            ML Selector
                â”‚
                â–¼
          Pipeline Engine
                â”‚
                â–¼
            Validator
                â”‚
                â–¼
            Explainer
```

---

## Tech Stack

| Tool                    | Choice                                  |
| ----------------------- | --------------------------------------- |
| Core                    Python 3.11, Rust (highâ€‘perf codecs)      |
| Compression             zstd, brotli, lzma, custom entropy coders |
| ML                      PyTorch, scikitâ€‘learn                     |
| RAG / Explainability    LangChain, Chroma, OpenAIâ€‘compatible LLM  |
| Web UI                  FastAPI, React + Tailwind                 |
  
---

## Repository Structure

```text
piedpiperx/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ selector/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ validator/
â”‚   â””â”€â”€ explainer/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ index/
â”‚   â””â”€â”€ chains/
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ runners/
â”‚   â””â”€â”€ graphs/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ public/
â”œâ”€â”€ scripts/
â”œâ”€â”€ docs/
â””â”€â”€ README.md
```

---

## ASCII Architecture Diagram

```text
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚   Web UI   â”‚
                             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                             â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                             â”‚  FastAPI   â”‚
                             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚      File Analyzer      â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ ML Strategy Model â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Pipeline Engine  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚    Lossless Validator   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   RAG Explainer   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ML Training Pipeline

1. Collect heterogeneous corpus
2. Extract statistical + structural features
3. Run all pipelines â†’ ground truth ratios
4. Train multiâ€‘label classifier + regressor
5. Validate on unseen file families
6. Persist model + feature schema

---

## RAG: Explaining Compression Failures

When compression underperforms:

> *"Why didnâ€™t this file compress?"*

The system retrieves:

* entropy theory
* similar historical files
* codec limitations

Then generates grounded explanations via LangChain.

---

## Toolâ€‘Aware Reasoning (Antiâ€‘Hallucination)

The explainer **cannot invent reasons**.

Rules:

* Every claim must cite retrieved docs
* Metrics are computed, not guessed
* Pipelines are executed before explanation

---

## Evaluation & Hallucination Metrics

**Compression Metrics**

* Ratio
* Time
* Memory

**ML Metrics**

* Topâ€‘1 accuracy
* Regret vs oracle

**RAG Metrics**

* Citation coverage
* Faithfulness score
* Contradiction rate

---

## Benchmarks

We benchmark against:

* ZIP
* TAR.GZ
* 7z
* Zstd

Graphs are autoâ€‘generated and versioned.

---

## Legal & Ethics

This project is:

* Inspired by fiction
* Implements real, known techniques
* Makes no impossible claims

---

## Roadmap

* GPUâ€‘assisted entropy analysis
* Streaming compression
* Distributed benchmarks
* Academic paper submission

---

## License

Apacheâ€‘2.0

---

## Final Note

**AULCE is a flagship portfolio project** meant to demonstrate:

* systems thinking
* ML + infra maturity
* scientific honesty

If it ever beats ZIP by 10Ã— on *your* dataâ€”great.
If it doesnâ€™tâ€”weâ€™ll explain *why*.
